{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYLhrQMRIr4h"
      },
      "source": [
        "# 4. Labor: Polinomiális Logisztikus regresszió Regularizációval\n",
        "\n",
        "A gyakorlat során megvizsgáljuk, hogyan lehet nem lineárisan elhatárolható csoportok közötti klasszifikációt elvégezni polynomiális regresszió segítségével, illetve hogyan lehet a modell súlyait regularizáció segítségével kézben tartani."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyVMlUtvIr4n"
      },
      "source": [
        "### Születés utáni komplikáció\n",
        "\n",
        "A gyakorlathoz tartozó adatsor 1000+ születés esetén tartalmazza a terhesség teljes hosszát napokban, illetve a születéskori testsúlyt kilogrammban. A cél az, hogy a modell ezek alapján megadja, mekkora az esély arra, hogy a baba fejlődésének korai szakaszában komplikációk fognak fellépni."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "beE_CxAeIr4p"
      },
      "source": [
        "## Alultanulás (underfitting)\n",
        "\n",
        "Az előző gyakorlat során alkalmazott Logisztikus regresszió egy lineáris modellt használt alapul. Bár a teljes modellt nevezhetjük nem linárisnak a _sigmoid_ függvény bevezetése miatt, a meghatározott döntési határ (_decision boundary_) a lineáris alap miatt egy egyenes volt. Ezzel viszonylag jól tudtuk modellezni az eredményeket, látható, hogy egy megfelelő görbe jobb eredményeket adhatna. Hasonló megfontolásokat tehetünk egy szimpla regressziós feladat esetében is.\n",
        "\n",
        "<!---\n",
        "<center><img src=\"img/linear_vs_poly.svg\" width=\"1200\"></center>\n",
        "-->\n",
        "<center><img src=\"https://raw.githubusercontent.com/MOGI-AI/adaptiv_labor/main/Lab04_polyLogReg_w_regularisation/img/linear_vs_poly.svg\" width=\"1200\"></center>\n",
        "\n",
        "Amennyiben a modellünk nem elég komplex az adatok által leírt összefüggések modellezzéséhez, a kapott végeredmény a valóság egy leegyszerűsített, nem pedig pontos modellje lesz (lineáris döntési határ görbe helyett), azaz a modell alultanult (underfit). A felhasználásunktól függően ez lehet, hogy megfelel a célnak, de lesznek olyan esetek, amikor szükséges a bonyolultabb modell bevezetése."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6GSyr2GIr4q"
      },
      "source": [
        "## Polinomiális regresszió\n",
        "\n",
        "Ahhoz, hogy a modell képes legyen görbe jellegű döntéshatárokat meghatározni, az alapul szolgáló lineáris illesztés helyett magasabb rendű, u.n. polinomiális regressziót kell alkalmazni.\n",
        "\n",
        "Lineáris regresszió két változóra:\n",
        "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2$$\n",
        "\n",
        "Polinomiális regresszió két változóra harmadrendű polinommal:\n",
        "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1^2 + w_4 x_1 x_2 + w_5 x_2 ^2 + w_6 x_1^3 + w_7 x_1^2 x_2 + w_8 x_1 x_2^2 + w_9 x_2^3$$\n",
        "\n",
        "A modellillesztés szempontjából azonban tekinthetünk a bemenetek magasabb rendű kombinációjára úgy, mintha új, független változók lennének:\n",
        "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + w_5 x_5 +\\dots + w_9 x_9$$\n",
        "ahol\n",
        "$$x_3 = x_1^2; \\quad x_4 = x_1 x_2; \\quad x_5 = x_2^2; \\quad x_6 = x_1^3; \\quad x_7 = x_1^2 x_2; \\quad x_8 = x_1 x_2^2; \\quad x_9 = x_2^3$$\n",
        "\n",
        "Az új változók definiálásával egy kétváltozós harmadrendű modell illesztésének folyamata teljesen megegyezik egy kilenc változós ténylegesen lineáris regresszió illesztésével, az eltérés csupán az értelmezésben van. A bemeneti adatpontok 2D-ben ábrázolhatók, nem kell 9 különböző dimenziót használni. Az illesztett modellt értelmezhető egy két változó feletti harmadrendű polinomként egy 9 dimenziós síkfelület helyett."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0hp5nRiqIr4s"
      },
      "source": [
        "## Túltanulás (overfitting)\n",
        "\n",
        "A bonyolultabb modell bevezetésével megjelenik a túltanulás veszélye, azaz a modell az adatok mögötti összefüggés helyett a konkrét adatpontokat tanulja meg. Így a tanítóadatokon való értékelés esetén azt látjuk, hogy nagyon jól teljesít a modell, azonban további, a tanításhoz nem használt adatokon szignifikánsan rosszabb a teljesítménye, elveszíti az általánosító képességét. A gépi tanulással megoldott problémák során mindig a bemenetek és kimenetek közötti összefüggés megtalálsa a cél, nem a konkrét adatpontok megtanulása. Bár a polinomiális logisztikus regresszió nem valószínű, hogy az ábrán látható mérétékű túltanulást fog mutatni, bonyolultabb, több nemlinearitást tartalmazó modellek (neurális hálók) esetében ez egy valós probléma lehet.\n",
        "\n",
        "<!---\n",
        "<center><img src=\"img/overfit.svg\" width=\"1200\"></center>\n",
        "-->\n",
        "<center><img src=\"https://raw.githubusercontent.com/MOGI-AI/adaptiv_labor/main/Lab04_polyLogReg_w_regularisation/img/overfit.svg\" width=\"1200\"></center>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0p6gIjEOIr4t"
      },
      "source": [
        "## Regularizáció\n",
        "\n",
        "Az eddigiekben a költségfüggvény egy szempontot vett figyelembe: a modell a lehető legpontosabban kövesse az illesztésre használt adatokat. Azonban lehetőség van a költségfüggvényben a pontos illesztés mellett más szempontokat is figyelembe venni, amivel a végleges súlyok jellege befolyásolható. Ezt a módszert **regularizációnak** nevezzük. A regularizáció használatakor a modell illesztésének jóságát mérő tag mellett egy regularizációs, vagyis büntető (_penalty_) taggal kerül kegészítésre a teljes költségfüggvény. Egy két osztályból álló klasszifikáció esetén a költségfüggvény általános alakja:\n",
        "$$C(\\mathbf{W}) = C_{BCE}(\\mathbf{W}) + \\lambda P(\\mathbf{W})$$\n",
        "ahol $C_{BCE}(w)$ a már előző gyakorlatról ismert Binary CrossEntropy költségfüggvény, $P(\\mathbf{W})$ a regularizációból származó büntető tag, $\\lambda$ pedig a büntető tag súlyozására használt paraméter.\n",
        "\n",
        "A költségfüggvény változásával a tanulás során használt gradiensvektor is változik.  Az összegfüggvény deriválási szabálya alapján\n",
        "$$\\nabla C (\\mathbf{W}) = \\nabla C_{BCE}(\\mathbf{W}) + \\lambda \\nabla P(\\mathbf{W})$$\n",
        "Így a regularizáció hasnzálatakor nincs más teendő, mint az eddigiekben számolt gradiens mellé a megfelelő büntető tag gradiensét hozzáadni, illetve a büntetés mértékét a $\\lambda$ paraméter segítségével beállítani. \n",
        "\n",
        "Az egyes regularizációs módszerek segítenek a modell túltanulását elkerülni, a modelleket a lehető legegyszerűbb vagy legáltalánosabb forma felé irányítani. A bias taghoz tartozó súlyt a feladattól függően nem mindig vetjük alá regularizációnak. A gyakorlat során kétféle regularizációs módszert nézünk meg.\n",
        "\n",
        "### L1 regularizáció (Lasso regularizáció)\n",
        "\n",
        "L1 regularizáció esetén a büntető tag a súlyok abszolút értékének összege:\n",
        "$$P_{L1}(\\mathbf{W}) = \\sum_{i=1}^n |w_i|$$\n",
        "\n",
        "A Lasso regularizáció így arra törekszik, hogy jó modellillesztés mellett a súlyok egyenként a lehető legkisebbek legyenek. Azok a súlyok, amelyek csak kis mértékben járulnak hozzá a modell jóságához a nullához fognak közelíteni. Az L1 regularizáció segíségével így a modell dimenziója 'csökkenthető', a nem releváns bemeneti paraméterek a meghatározott közel zérus súlyok alapján elhagyhatók. A végső illesztés esetében csak azok a súlyok maradnak fenn, amelyek szignifikánsan hozzájárulnak a kimenő változó magyarázásához. A modell így egyszerűsíthető, a modellillesztés mellet dimenzióredukciót is végzünk.\n",
        "\n",
        "Az L1 regularizáció esetén a gradiensvektor keigészítő tagja az egyes súlyok szignuma:\n",
        "$$ \\nabla P_{L1}(\\mathbf{W}) = sgn(\\mathbf{W})$$\n",
        "Ez alapján könnyen látható, hogy minden súlyt azok nagyságától függetlenül a 0 felé igyekszik eltolni.\n",
        "\n",
        "### L2 regularizáció (Ridge regularizáció)\n",
        "\n",
        "L2 regularizáció esetén a büntető tag a súlyok négyzetének összege (az $\\frac{1}{2}$-es szorzó csak a szebb gradiens céljából van jelen):\n",
        "$$ P_{L2}(\\mathbf{W}) = \\frac{1}{2}\\sum_{i=1}^n w_i^2 $$\n",
        "\n",
        "A Ridge regularizáció így arra törekszik, hogy jó modellillesztés mellett kerülje a nagy súlyok használatát. A négyzetre emelés miatt a kissebb, közeli súlyokat nem bünteti annyira, a nagyobb súlyokat viszont jelentősen jobban bünteti mint az L1 regularizáció. Az optimlizáció igy igyekszik eggyik bemenetre sem túlságosan támaszkodni. Ezzel növelhető a modell robosztussága és általánosító képessége.\n",
        "\n",
        "Az L2 regularizáció esetén a gradiensvektor kiegészítő tagjai maguk a súlyok:\n",
        "$$ \\nabla P_{L2}(\\mathbf{W}) = \\mathbf{W}$$\n",
        "Látható, hogy ebben az esetben a regularizáció a súly nagyságával arányosan bünteti azt, azaz a nagyobb súlyra nagyobb a büntetés, kis súly esetén azonban nem annyira jelentős. Ezek együttes hatás így az, hogy igyekszik minden súlyt kis értéken tartani."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMKWtTBhIr4v"
      },
      "source": [
        "## 00: Könyvtár importálások\n",
        "\n",
        "Első lépésként importáljuk a feladat megoldása során használt könyvtárakat. Esetünkben ezek a következők lesznek:\n",
        "- Numpy a matematikai műveletek elvégzéséhez\n",
        "- Pandas az adatok beolvasásához és kezeléséhez\n",
        "- MatPlotLib.pyplot az eredményeink ábrázolásához\n",
        "- Plotly Express interaktív vizualizációhoz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTFhfOdVIr4w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Használjuk ezeket sötét téma esetén\n",
        "plt.style.use('dark_background')\n",
        "styleTemplate = 'plotly_dark'\n",
        "\n",
        "# Használjuk ezeket világos téma esetén\n",
        "#plt.style.use('default')\n",
        "#styleTemplate = 'plotly_white'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7nS2azyIr4z"
      },
      "source": [
        "## 01: Adatbeolvasás\n",
        "Olvassuk be a szükséges adatokat az ```birthData.txt``` fájlból."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uX9bjPDhIr40",
        "outputId": "92bfdb69-b685-494f-a0eb-9262457d1576"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('birthData.txt', sep = ',', header = 0)    # Olvassuk be az adatokat egy Pandas DataFrame ojektumba\n",
        "df.head(10)                                                 # Irassuk ki az első 10 sort, hogy ellenőrizzük sikerült-e a beolvasás"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YZknH1IwIr41"
      },
      "source": [
        "## 02: Adatfelfedezés\n",
        "\n",
        "Új adathalmazzal történő első interrakció során érdemes először azt megvizsgálni, alapvető vizualizációkon ábrázolni, hogy legyen egy elsődleges \"benyomás\" az adatok jellegéről. Ábrázoljuk az adatokat egy X-Y diagrammon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "TneiNrV5Ir42",
        "outputId": "25b48748-4a0d-4ae0-a08d-5ae0d2665954"
      },
      "outputs": [],
      "source": [
        "# Formális vizualizáció MatPlotLib-el\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.scatter(df[df['complication'] == 0]['gestation'], df[df['complication'] == 0]['birthweight'], marker='o',c=\"green\", label=\"Egészséges\")\n",
        "plt.scatter(df[df['complication'] == 1]['gestation'], df[df['complication'] == 1]['birthweight'], marker='x',c=\"tomato\", label=\"Komplikáció\")\n",
        "\n",
        "plt.title(\"Születés utáni komplikációk\")\n",
        "plt.xlabel(\"Terhességi napok száma\")\n",
        "plt.ylabel(\"Születési testtömeg [kg]\")\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV7c9b-2Ir43"
      },
      "source": [
        "Ez alapján látható, hogy igen nehéz lenne egy egyenes segítségével egy jó határvonalat illeszteni az adatokra, mindenképpen magasabb rendű modellt érdemes alkalmazni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFk3oVAKIr43"
      },
      "source": [
        "## 03: Adatok előkészítése\n",
        "\n",
        "A beolvasott pandas adattáblából a tanító bementeket és kimeneteket mátrixokba rendezzük."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjdRwRbpIr44",
        "outputId": "b7a802a3-27e7-41ce-c49c-b002fb0109d6"
      },
      "outputs": [],
      "source": [
        "X = df[['gestation', 'birthweight']].to_numpy()   # Bemeneti változók oszlopainak kiemelése és tömbbé konvertálása\n",
        "Y = df[['complication']].to_numpy()               # Kimeneti változó oszlopának kiemelése és tömbbé konvertálása\n",
        "\n",
        "m,n = X.shape   \n",
        "print('X:',X.shape)                               # adattömbök méretének / adatok számának kiírása\n",
        "print('Y:',Y.shape)\n",
        "print('Adatok száma',m)\n",
        "print('Változók (Feature) száma:',n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQaURM9_Ir44"
      },
      "source": [
        "A polinomiális regresszió alkalmazásához a bementi adatmátrixot ki kell bővíteni az adatok magasabb rendű kombinációival. Harmadrendű polinom esetén például:\n",
        "$$x_1,\\  x_2 \\Rightarrow\\ 1,\\ x_1,\\ x_2,\\ x_1^2,\\ x_1x_2,\\ x_2^2,\\ x_1^3,\\ x_1^2x_2,\\ x_1x_2^2,\\ x_2^3$$\n",
        "\n",
        "**Feladat:** implementálja a ```mapFeatures()``` függvényt, amely a **két** bemeneti változó alapján legenerálja a teljes bementei mátrixot tetszőleges fokszám esetére!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrHOuIWOIr45"
      },
      "outputs": [],
      "source": [
        "def mapFeatures(X, deg = 3):                         \n",
        "# Bemeneti változók létrehozása polinomiális regresszióhoz\n",
        "#######################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######################################################            \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhdGXAqnIr46",
        "outputId": "17ace7d6-31ed-4052-df55-ac5874006f87"
      },
      "outputs": [],
      "source": [
        "deg = 5                     # tesztelés ötödrendű polinomra\n",
        "X=mapFeatures(X, deg)       # vátozók kibővítése \n",
        "if X.shape[1] != 21:        # ellenőrzés\n",
        "    print(\"Az X mátrixban található változók száma nem megfelelő. Ellenőrizze a mapFeatures() függvény implementációját!\")\n",
        "else:\n",
        "    print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7-9SCELIr46"
      },
      "source": [
        "Az újonnan előállított bemeneti adatokat normalizálni is kell (a bias változót leszámítva). Fontos, hogy ez a kibővítés után történjen, mivel fordított sorrend esetén előfordulhatnak jelentősen eltérő nagyságrendbe eső adatk a bővítésénél alkalmazott magasabb hatványok miatt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MKMrI8eIr47",
        "outputId": "88b7fa9c-be46-4281-a4e8-82089cb1749c"
      },
      "outputs": [],
      "source": [
        "def featureNormalize(Z): \n",
        "    mean = np.mean(Z, axis = 0)\n",
        "    mean[0] = 0\n",
        "    sigma = np.std(Z, axis = 0)\n",
        "    sigma[0] = 1\n",
        "    Z_norm = (Z-mean)/sigma\n",
        "    return Z_norm, mean, sigma                            \n",
        "\n",
        "print('Bemeneti adatok normalizálása ... \\n')                    \n",
        "X,Xmean,Xsigma = featureNormalize(X)                      # X standardizálása\n",
        "scaleFactors = {\"Xmean\" : Xmean, \"Xsigma\" : Xsigma}\n",
        "print('Átlagos terhességhossz és születési testtömeg:', Xmean[1:3])\n",
        "print('Terhességhossz és születési testtömeg szórása:', Xsigma[1:3], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fikng_nQIr48"
      },
      "source": [
        "## 04: Modell definiálása\n",
        "\n",
        "Az adatok előkészítése utáni következő lépés a modell és tanítási logika definiálása."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX2BOrpmIr48"
      },
      "outputs": [],
      "source": [
        "# Szigmoid aktivációs függvény\n",
        "def sigmoid(z):              \n",
        "    return 1/(1+np.exp(-z))                              "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJPFFwBmIr49"
      },
      "source": [
        "Bár a regularizáció miatt eltérő a tényleges költségfüggvény ami minimalizálásra kerül, a különböző illesztések összehasonlíthatósága érdekében a modell értékelésére az eredeti **BCE** költségfüggvényt használjuk. Így a tanítás során a költségfüggvény alakulása a tényleges illesztés jóságát fogja visszaadni a modellek értékelésére."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zzx3IA-Ir49"
      },
      "outputs": [],
      "source": [
        "# Költségfüggvény\n",
        "def costBCE(X,Y,W):\n",
        "   eps = 1e-15    # log(0) számításának elkerülésére\n",
        "   yHat = sigmoid(X@W)\n",
        "   m = Y.shape[0]\n",
        "   C = np.mean((-Y*np.log(yHat+eps))-(1-Y)*np.log(1-yHat+eps))\n",
        "   return C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bKR8xZTIr4-"
      },
      "source": [
        "A gradiensvektor számolása esetén azonban már figyelembe kell venni a regularizációt.\n",
        "\n",
        "**Feladat:** implementálja a gradiensvektor számítását, amely a 'regu' pareméter értékétől függően (```'None', 'L1', 'L2'```) a megfelelő gradiensvektorral tér vissza!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfyxmsNSIr4_"
      },
      "outputs": [],
      "source": [
        "# Gradiensvektor\n",
        "def findGradient(X,Y,W, lmbd, regu):    \n",
        "#######################################################   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######################################################\n",
        "   return grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW_Z59lUIr4_",
        "outputId": "98d3e501-27ad-4e50-8c00-4c36b3ffdd54"
      },
      "outputs": [],
      "source": [
        "# Regularizált gradiensek tesztelése\n",
        "print('''Az modell első három súlyára (bias, X1, X2) vonatkozó gradiensek \n",
        "elvárt értékei regularizáció nélkül, illetve L1 és L2 regularizáció mellett:\n",
        "[[0.68212698]\n",
        " [0.13627374]\n",
        " [0.16772988]]\n",
        "[[ 0.68212698]\n",
        " [ 1.13627374]\n",
        " [-0.83227012]]\n",
        "[[ 0.68212698]\n",
        " [ 1.01057374]\n",
        " [-0.45577012]]''')\n",
        "print()\n",
        "print('''Ugyanezen esetekre a számolt gradiens:''')\n",
        "W = np.array([[1.645], [0.8743], [-0.6235]])\n",
        "print(findGradient(X[:,:3], Y, W, lmbd = 1, regu='None'))\n",
        "print(findGradient(X[:,:3], Y, W, lmbd = 1, regu='L1'))\n",
        "print(findGradient(X[:,:3], Y, W, lmbd = 1, regu='L2'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyTD9oUrIr5A"
      },
      "source": [
        "A regularizált polinomiális logisztikus regresszió implementálásának utolsó lépése az iterációs logika implementálása a megflelő regularizációt tartalamazó gradinesekkel.\n",
        "\n",
        "**Feladat:** Készítse el a regularizált logisztikus regresszió problémájat gradiens módszerrel megoldó algoritmust! Az algoritmus számolja ki a kezdeti, majd minden iteráció utáni költéségfüggvény értéket is!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf_5ABXsIr5B"
      },
      "outputs": [],
      "source": [
        "def logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, regu = 'None'):\n",
        "    C_history = np.zeros(epochs+1)\n",
        "    C_history[0] = costBCE(X,Y,W)\n",
        "######################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################################################\n",
        "    return W,C_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzTlDhQWIr5B"
      },
      "source": [
        "A modell viselkedésének elemzéséhez futtassuk le a tanítást azonos paraméterek mellett mindhárom regularizációs módszerrel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "JJk66AwkIr5C",
        "outputId": "bb47b3b9-08f9-4d3a-98cd-682172b24565"
      },
      "outputs": [],
      "source": [
        "print('Gradiens algoritmus futtatása ...')\n",
        "epochs = 250            # epoch szám\n",
        "lmbd = 0.02             # Lambda (regularizáció súlya)\n",
        "learning_rate = 0.5     # tanulási ráta\n",
        "W = np.zeros([X.shape[1],1])  # kezdeti zérus súlyok (0;0;0)\n",
        "\n",
        "W_n, C_history_n = logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, 'None')                             \n",
        "plt.plot(range(C_history_n.size), C_history_n, label= \"No regularization\", c=\"red\")\n",
        "                                                       \n",
        "W_L1, C_history_L1 = logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, 'L1')                             \n",
        "plt.plot(range(C_history_L1.size), C_history_L1, label= \"L1 regularization\", c=\"green\")\n",
        "\n",
        "W_L2, C_history_L2 = logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, 'L2')\n",
        "plt.plot(range(C_history_L2.size), C_history_L2, label= \"L2 regularization\", c=\"blue\")              \n",
        "\n",
        "plt.title(\"Különböző regularizációk hatása a költségfüggvény alakulására\")\n",
        "plt.xlabel(\"Iteráció\")\n",
        "plt.ylabel(\"BCE költség\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MIQ2LV2aIr5D"
      },
      "source": [
        "Az modellünk alkalmazhatóságához és az illesztés vizsgálatához szükséges még a predict függvény, amely adott valós bemenetre (terhesség hossza napokban és újszülött súlya kilogrammban) visszatér a komplikáció valószínűségével.\n",
        "\n",
        "**Feladat**: implementálja a predict függvényt a regularizált polinomiális logisztikus regresszió esetére! Ügyeljen rá, hogy a valószínűség bescslése előtt bemeneteket most is bővíteni majd normalizálni kell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUMSz7xAIr5D",
        "outputId": "1440a37a-94dc-42ba-dc9d-3cef2eec4144"
      },
      "outputs": [],
      "source": [
        "def predict(X, W, deg, scaleFactors):              # predikciós függvény\n",
        "###########################################    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###########################################    \n",
        "   return prob, pred                                    \n",
        "\n",
        "testScore = np.array([[312,3.176]])\n",
        "prob, pred = predict(testScore, W_n, deg, scaleFactors)            # 312 nap terhesség után 3,176 kg-al született baba komplikációs valőszínűsége\n",
        "print('''A [312 , 3.176] teszteredményekre elvárt kimenet:\n",
        "Nincs komplikáció (0), p = 0.232 valószínűséggel\n",
        "Számított: %.0f; %.4f valószínűséggel''' % (pred, prob))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "mEjEL9j5Ir5E",
        "outputId": "ccd6a7b4-b19f-48d7-a32b-ee6de6a0273a"
      },
      "outputs": [],
      "source": [
        "# Formális vizualizáció MatPlotLib-el\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "# Eredeti adatpontok ábrázolása\n",
        "plt.scatter(df[df['complication'] == 0]['gestation'], df[df['complication'] == 0]['birthweight'], marker='o',c=\"green\", label=\"Egészséges\")\n",
        "plt.scatter(df[df['complication'] == 1]['gestation'], df[df['complication'] == 1]['birthweight'], marker='x',c=\"tomato\", label=\"Komplikáció\")\n",
        "\n",
        "x1 = np.linspace(min(df['gestation'])-50, max(df['gestation']+10), 200)          # grid létrehozása\n",
        "x2 = np.linspace(min(df['birthweight'])-0.2, max(df['birthweight']+1.2), 200)    # második paraméter\n",
        "\n",
        "z_n=np.zeros((len(x1),len(x2)))                          # eredményváltozó 1 inicializálása\n",
        "z_L1=np.zeros((len(x1),len(x2)))                         # eredményváltozó 2  inicializálása\n",
        "z_L2=np.zeros((len(x1),len(x2)))                         # eredményváltozó 3  inicializálása\n",
        "\n",
        "for i in range(len(x1)):                                 # valószínűség számolása a teljes háló felett\n",
        "    for j in range(len(x2)):     \n",
        "        testPoint = np.array([[x1[i], x2[j]]])\n",
        "        z_n[i,j], _ = predict(testPoint, W_n, deg, scaleFactors)\n",
        "        z_L1[i,j], _ = predict(testPoint, W_L1, deg, scaleFactors)\n",
        "        z_L2[i,j], _ = predict(testPoint, W_L2, deg, scaleFactors)\n",
        "\n",
        "plt.contour(x1, x2,z_n.transpose(), 0, colors='red')                                  # kirajzoljuk contour plottal a döntési határt\n",
        "plt.contour(x1, x2, z_L1.transpose(), 0, colors='green')                                  # kirajzoljuk contour plottal a döntési határt\n",
        "plt.contour(x1, x2, z_L2.transpose(), 0, colors='blue')                                  # kirajzoljuk contour plottal a döntési határt\n",
        "\n",
        "plt.title(\"Születés utáni komplikációk\")\n",
        "plt.xlabel(\"Terhesség napjainak száma\")\n",
        "plt.ylabel(\"Születési testtömeg [kg]\")\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKfYGP75Ir5F"
      },
      "source": [
        "A modell viselkedésének teljes megértése érdekében érdemes nem csak a döntési határt, hanem a teljes illesztett felületet is ábrázolni. A 6. sor `z` paraméterének változtatásával kiválaszthatjuk melyik modell kerüljön ábrázolásra, így jobban megérthető a a fentebb látott költségfüggvény alakulás, és az előbbi döntéshatárok közötti ellentmondás oka."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "QVtJuGGPIr5F",
        "outputId": "bf5531c8-e1c1-4f0d-a9cf-92815099989c"
      },
      "outputs": [],
      "source": [
        "# Ábrázolás Plotly-val\n",
        "fig = go.Figure()\n",
        "\n",
        "# A magyarázott változót transzponálni kell a helyes megjelenítésért.\n",
        "fig.add_trace(go.Scatter3d(x=df['gestation'], y=df['birthweight'], z=df['complication'], mode= \"markers\"))\n",
        "fig.add_trace(go.Surface(x=x1, y=x2, z=z_n.T, colorscale ='Blues'))\n",
        "\n",
        "#Plot formázása\n",
        "fig.update_layout(\n",
        "    title = \"Felvétel esélyének becslése\",\n",
        "    scene = dict(\n",
        "        xaxis_title = \"Terhesség napjainak száma\",\n",
        "        yaxis_title = \"Születési testtömeg [kg]\",\n",
        "        zaxis_title = \"Komplikáció valószínűsége\"),\n",
        "    template=styleTemplate,\n",
        "    width=750,\n",
        "    height=500,\n",
        ")\n",
        "\n",
        "#Plot megjelenítése\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E87gTKc9Ir5G"
      },
      "source": [
        "Az egyes regularizációs módszerek hatásának vizsgálatához nézzük meg, hogy a súlyok hogyan alakulnak az egyes módszerekkel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkQ3J2qMIr5H",
        "outputId": "5ea8d4bf-9cad-490d-c88e-2c40ef4e21b2"
      },
      "outputs": [],
      "source": [
        "print('''A modell végső súlyai regularizáció nélkül''')\n",
        "for (loc, value) in enumerate(W_n):\n",
        "    if np.abs(value) < 0.1:\n",
        "        W_n[loc] = 0.0\n",
        "print(W_n)\n",
        "print()\n",
        "\n",
        "print('''A modell végső súlyai L1 regularizációval''')\n",
        "for (loc, value) in enumerate(W_L1):\n",
        "    if np.abs(value) < 0.1:\n",
        "        W_L1[loc] = 0.0\n",
        "print(W_L1)\n",
        "print()\n",
        "\n",
        "print('''A modell végső súlyai L2 regularizációval''')\n",
        "for (loc, value) in enumerate(W_L2):\n",
        "    if np.abs(value) < 0.1:\n",
        "        W_L2[loc] = 0.0\n",
        "print(W_L2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XX: Megoldás a Scikit-learn könyvtár segítségével\n",
        "\n",
        "A feladat az eddigiekhez hasonló módon megoldható egy magasabb szintű könyvtár által implementált modellel is, bár az eddigiektől eltérően már nem kulcsrakész megoldás áll rendelkezésre. A feladat megoldása két lépésben történik, első a polinomiális bemenetei változókra történő bővítés, majd második a logisztikus regresszió megoldása."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "df = pd.read_csv('birthData.txt', sep = ',', header=0)          # adatok beolvasása\n",
        "XX = df[['gestation', 'birthweight']].to_numpy()                # adatok szétválogatása\n",
        "YY = df['complication'].to_numpy()                              # adatok szétválogatása (LogReg fit-je egy 1d tömböt vár!)\n",
        "\n",
        "poly = PolynomialFeatures(degree = 5, interaction_only=False, include_bias=False)   # LogisticRegression hozzáteszi a Bias változót\n",
        "XX_poly = poly.fit_transform(XX)                                # polynomiális változók generálása\n",
        "\n",
        "standard = StandardScaler()\n",
        "XX_standard = standard.fit_transform(XX_poly)                   # standardizálás\n",
        "\n",
        "logReg = LogisticRegression(penalty = None, max_iter=250, solver='sag').fit(XX_standard,YY)         # penalty --> regularizáció (lehet 'l1', 'l2' is)\n",
        "\n",
        "test = np.array([[312,3.176]])                                  # mivel egy mintánk van ezért (1,2) array kell ezért a dupla []\n",
        "test_poly = poly.transform(test)                                # polynomiális változók generálása\n",
        "test_standard = standard.transform(test_poly)                   # standardizálás\n",
        "\n",
        "pred = logReg.predict(test_standard)                            # kimenetel becslése\n",
        "pred_p = logReg.predict_proba(test_standard)                    # a teszteset valszínűségi predikciója\n",
        "\n",
        "print(\"\"\"Prediction for complications in early development:\"\"\",int(pred),\"\"\"\n",
        "The value of the probability:\"\"\",pred_p[0,1])\n",
        "\n",
        "acc = logReg.score(XX_standard,YY)                               # pontosság kiszámolása\n",
        "print('')\n",
        "print('Accuracy on the training data:',acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
